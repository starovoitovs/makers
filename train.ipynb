{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import yaml\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from makers.model import build_model\n",
    "from makers.utils import prepare, get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"_input/data/book-COINBASE-BTC-USD.csv\"\n",
    "CONFIG_PATH = \"_input/config.yml\"\n",
    "OUTDIR = '_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config = yaml.safe_load(open(CONFIG_PATH, 'r'))\n",
    "\n",
    "# specify paths\n",
    "model_name = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_dir = os.path.join(OUTDIR, 'models', model_name)\n",
    "model_path = os.path.join(model_dir, 'model.h5')\n",
    "metrics_path = os.path.join(model_dir, 'metrics.txt')\n",
    "config_path = os.path.join(model_dir, 'config.yml')\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling\n",
    "\n",
    "There are three labels: buy, hold and sell. The classes are imbalanced as there are many more hold samples compared to the other ones. In order to equalize the classes, one needs to either undersample the majority class, or oversample the minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(df, scaler, depth, window_size):\n",
    "    \n",
    "    slice_step = len(df) // np.sum(df['signal'] != 0) // 2 if np.sum(df['signal'] != 0) > 0 else 1\n",
    "    idx = df[df['signal'] != 0].index.to_list() + df[df['signal'] == 0][::slice_step].index.to_list()\n",
    "    idxnum = [df.index.get_loc(x) for x in idx if df.index.get_loc(x) > window_size]\n",
    "\n",
    "    # get samples\n",
    "    X1 = prepare(df, idxnum, depth, window_size)\n",
    "\n",
    "    # rescale\n",
    "    n_samples = X1.shape[0]\n",
    "    X1[:] = scaler.fit_transform(X1[:, :, :, 0].reshape((n_samples, -1))).reshape(\n",
    "        (n_samples, window_size, depth * 4, 1))\n",
    "\n",
    "    # encode labels\n",
    "    y = df['signal'].iloc[idxnum].to_numpy()\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    y = enc.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "    # otherwise some classes are missing\n",
    "    assert y.shape[1] == 3, \"Some classes are missing.\"\n",
    "\n",
    "    # NB: shuffle=True has look-ahead bias!\n",
    "    X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "    return X1_train, X1_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(df, scaler, depth, window_size):\n",
    "    \n",
    "    slice_step = 10\n",
    "    idx = df[df['signal'] != 0].index.to_list() + df[df['signal'] == 0][::slice_step].index.to_list()\n",
    "    idxnum = [df.index.get_loc(x) for x in idx if df.index.get_loc(x) > window_size]\n",
    "\n",
    "    # get samples\n",
    "    X1 = prepare(df, idxnum, depth, window_size)\n",
    "\n",
    "    # rescale\n",
    "    n_samples = X1.shape[0]\n",
    "    X1[:] = scaler.fit_transform(X1[:, :, :, 0].reshape((n_samples, -1))).reshape(\n",
    "        (n_samples, window_size, depth * 4, 1))\n",
    "\n",
    "    # encode labels\n",
    "    y = df['signal'].iloc[idxnum].to_numpy()\n",
    "    enc = OneHotEncoder(sparse=False)\n",
    "    y = enc.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "    # otherwise some classes are missing\n",
    "    assert y.shape[1] == 3, \"Some classes are missing.\"\n",
    "\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "    X1, y = ros.fit_resample(X1.reshape((n_samples, -1)), y)\n",
    "\n",
    "    n_samples = X1.shape[0]\n",
    "    X1 = X1.reshape((n_samples, window_size, 4 * depth, 1))\n",
    "\n",
    "    # NB: shuffle=True has look-ahead bias!\n",
    "    X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "    return X1_train, X1_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is sampled at 50ms. Each timestep has a UTC timestamp and 40 features: bid price and volume and ask price and volume, 10 levels deep.\n",
    "\n",
    "Labels are quantized as follows:\n",
    "* if the maximum ask price over the next 5 seconds - current ask price > threshold, label is +1\n",
    "* if the current bid price - minimum bid price over the next 5 seconds > threshold, label is -1\n",
    "* 0, otherwise\n",
    "\n",
    "So thus it's a classification, and not a regression task (which is more common AFAIK), but we could build a regression model too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset _input/book-COINBASE-BTC-USD.csv.\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "print(f'Loading dataset {DATA_PATH}.')\n",
    "df = pd.read_csv(DATA_PATH, index_col='timestamp', parse_dates=True).sort_index()\n",
    "\n",
    "# dedupe\n",
    "df = df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the fact that data is sampled at 50ms\n",
    "min_periods = config['model']['prediction_horizon'] * 1000 / 50\n",
    "\n",
    "print(f'Calculating labels.')\n",
    "\n",
    "# calculate indicators (use [::-1] to have rolling windows for successive, not trailing timesteps)\n",
    "df['p+'] = df['ap0'][::-1].rolling(td, min_periods=min_periods).max()[::-1] - df['ap0']\n",
    "df['p-'] = df['bp0'] - df['bp0'][::-1].rolling(td, min_periods=min_periods).min()[::-1]\n",
    "\n",
    "# remove na\n",
    "df = df[~df.isna().any(axis=1)]\n",
    "\n",
    "# calculate labels\n",
    "df['signal'] = (df['p+'] > config['model']['threshold']).astype(int) - (df['p-'] > config['model']['threshold']).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are imbalanced, resampling to equalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 15187.,      0.,      0.,      0.,      0., 666145.,      0.,\n",
       "             0.,      0.,  17356.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample and split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "assert config['model']['resampling'] in 'undersample', 'oversample'\n",
    "\n",
    "if config['model']['resampling'] == 'undersample':\n",
    "    X1_train, X1_test, y_train, y_test = undersample(df, scaler, config['model']['depth'], config['model']['window_size'])\n",
    "elif config['model']['resampling'] == 'oversample':\n",
    "    X1_train, X1_test, y_train, y_test = oversample(df, scaler, config['model']['depth'], config['model']['window_size'])\n",
    "    \n",
    "plt.hist(np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_output/models/20220214_155018/scaler1.h5']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump scaler into file\n",
    "scaler_path = os.path.join(model_dir, 'scaler1.h5')\n",
    "joblib.dump(scaler, scaler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1062/1062 - 7s - loss: 1.0265 - accuracy: 0.4717 - val_loss: 1.5475 - val_accuracy: 0.3554\n",
      "Epoch 2/50\n",
      "1062/1062 - 6s - loss: 0.9204 - accuracy: 0.5649 - val_loss: 1.0602 - val_accuracy: 0.4810\n",
      "Epoch 3/50\n",
      "1062/1062 - 6s - loss: 0.8080 - accuracy: 0.6393 - val_loss: 1.5799 - val_accuracy: 0.4152\n",
      "Epoch 4/50\n",
      "1062/1062 - 6s - loss: 0.7218 - accuracy: 0.6862 - val_loss: 1.1044 - val_accuracy: 0.5619\n",
      "Epoch 5/50\n",
      "1062/1062 - 5s - loss: 0.6629 - accuracy: 0.7158 - val_loss: 0.9589 - val_accuracy: 0.6294\n",
      "Epoch 6/50\n",
      "1062/1062 - 6s - loss: 0.6146 - accuracy: 0.7415 - val_loss: 1.0686 - val_accuracy: 0.5885\n",
      "Epoch 7/50\n",
      "1062/1062 - 6s - loss: 0.5793 - accuracy: 0.7599 - val_loss: 0.7728 - val_accuracy: 0.6753\n",
      "Epoch 8/50\n",
      "1062/1062 - 5s - loss: 0.5491 - accuracy: 0.7737 - val_loss: 0.6207 - val_accuracy: 0.7141\n",
      "Epoch 9/50\n",
      "1062/1062 - 6s - loss: 0.5275 - accuracy: 0.7840 - val_loss: 0.6210 - val_accuracy: 0.7420\n",
      "Epoch 10/50\n",
      "1062/1062 - 5s - loss: 0.5085 - accuracy: 0.7941 - val_loss: 1.0056 - val_accuracy: 0.5916\n",
      "Epoch 11/50\n",
      "1062/1062 - 5s - loss: 0.4925 - accuracy: 0.8001 - val_loss: 0.4760 - val_accuracy: 0.8005\n",
      "Epoch 12/50\n",
      "1062/1062 - 5s - loss: 0.4777 - accuracy: 0.8084 - val_loss: 0.5224 - val_accuracy: 0.7834\n",
      "Epoch 13/50\n",
      "1062/1062 - 6s - loss: 0.4638 - accuracy: 0.8139 - val_loss: 0.4817 - val_accuracy: 0.8028\n",
      "Epoch 14/50\n",
      "1062/1062 - 6s - loss: 0.4563 - accuracy: 0.8194 - val_loss: 0.5982 - val_accuracy: 0.7399\n",
      "Epoch 15/50\n",
      "1062/1062 - 5s - loss: 0.4444 - accuracy: 0.8243 - val_loss: 0.4750 - val_accuracy: 0.8020\n",
      "Epoch 16/50\n",
      "1062/1062 - 6s - loss: 0.4343 - accuracy: 0.8295 - val_loss: 0.5586 - val_accuracy: 0.7815\n",
      "Epoch 17/50\n",
      "1062/1062 - 6s - loss: 0.4220 - accuracy: 0.8343 - val_loss: 0.5785 - val_accuracy: 0.7631\n",
      "Epoch 18/50\n",
      "1062/1062 - 6s - loss: 0.4179 - accuracy: 0.8381 - val_loss: 0.5822 - val_accuracy: 0.7566\n",
      "Epoch 19/50\n",
      "1062/1062 - 5s - loss: 0.4072 - accuracy: 0.8417 - val_loss: 0.4270 - val_accuracy: 0.8241\n",
      "Epoch 20/50\n",
      "1062/1062 - 5s - loss: 0.4000 - accuracy: 0.8455 - val_loss: 0.5464 - val_accuracy: 0.7825\n",
      "Epoch 21/50\n",
      "1062/1062 - 6s - loss: 0.3938 - accuracy: 0.8481 - val_loss: 0.5061 - val_accuracy: 0.7981\n",
      "Epoch 22/50\n",
      "1062/1062 - 6s - loss: 0.3904 - accuracy: 0.8502 - val_loss: 0.4264 - val_accuracy: 0.8260\n",
      "Epoch 23/50\n",
      "1062/1062 - 6s - loss: 0.3876 - accuracy: 0.8518 - val_loss: 0.4788 - val_accuracy: 0.7941\n",
      "Epoch 24/50\n",
      "1062/1062 - 6s - loss: 0.3780 - accuracy: 0.8558 - val_loss: 0.4214 - val_accuracy: 0.8315\n",
      "Epoch 25/50\n",
      "1062/1062 - 5s - loss: 0.3801 - accuracy: 0.8560 - val_loss: 0.4497 - val_accuracy: 0.8120\n",
      "Epoch 26/50\n",
      "1062/1062 - 5s - loss: 0.3704 - accuracy: 0.8586 - val_loss: 0.4272 - val_accuracy: 0.8330\n",
      "Epoch 27/50\n",
      "1062/1062 - 5s - loss: 0.3678 - accuracy: 0.8608 - val_loss: 0.4347 - val_accuracy: 0.8168\n",
      "Epoch 28/50\n",
      "1062/1062 - 6s - loss: 0.3630 - accuracy: 0.8622 - val_loss: 0.4035 - val_accuracy: 0.8375\n",
      "Epoch 29/50\n",
      "1062/1062 - 6s - loss: 0.3578 - accuracy: 0.8652 - val_loss: 0.3660 - val_accuracy: 0.8581\n",
      "Epoch 30/50\n",
      "1062/1062 - 6s - loss: 0.3571 - accuracy: 0.8652 - val_loss: 0.4740 - val_accuracy: 0.8064\n",
      "Epoch 31/50\n",
      "1062/1062 - 5s - loss: 0.3575 - accuracy: 0.8650 - val_loss: 0.4574 - val_accuracy: 0.8147\n",
      "Epoch 32/50\n",
      "1062/1062 - 6s - loss: 0.3523 - accuracy: 0.8668 - val_loss: 0.4103 - val_accuracy: 0.8367\n",
      "Epoch 33/50\n",
      "1062/1062 - 5s - loss: 0.3457 - accuracy: 0.8708 - val_loss: 0.4043 - val_accuracy: 0.8434\n",
      "Epoch 34/50\n",
      "1062/1062 - 5s - loss: 0.3471 - accuracy: 0.8693 - val_loss: 0.3896 - val_accuracy: 0.8492\n",
      "Epoch 35/50\n",
      "1062/1062 - 6s - loss: 0.3450 - accuracy: 0.8701 - val_loss: 0.4516 - val_accuracy: 0.8229\n",
      "Epoch 36/50\n",
      "1062/1062 - 6s - loss: 0.3411 - accuracy: 0.8714 - val_loss: 0.4107 - val_accuracy: 0.8391\n",
      "Epoch 37/50\n",
      "1062/1062 - 5s - loss: 0.3385 - accuracy: 0.8732 - val_loss: 0.3919 - val_accuracy: 0.8400\n",
      "Epoch 38/50\n",
      "1062/1062 - 6s - loss: 0.3363 - accuracy: 0.8750 - val_loss: 0.3635 - val_accuracy: 0.8639\n",
      "Epoch 39/50\n",
      "1062/1062 - 6s - loss: 0.3338 - accuracy: 0.8753 - val_loss: 0.3684 - val_accuracy: 0.8494\n",
      "Epoch 40/50\n",
      "1062/1062 - 6s - loss: 0.3313 - accuracy: 0.8769 - val_loss: 0.3835 - val_accuracy: 0.8467\n",
      "Epoch 41/50\n",
      "1062/1062 - 6s - loss: 0.3280 - accuracy: 0.8788 - val_loss: 0.4108 - val_accuracy: 0.8428\n",
      "Epoch 42/50\n",
      "1062/1062 - 6s - loss: 0.3277 - accuracy: 0.8792 - val_loss: 0.3848 - val_accuracy: 0.8567\n",
      "Epoch 43/50\n",
      "1062/1062 - 6s - loss: 0.3266 - accuracy: 0.8789 - val_loss: 0.3871 - val_accuracy: 0.8457\n",
      "Epoch 44/50\n",
      "1062/1062 - 6s - loss: 0.3226 - accuracy: 0.8799 - val_loss: 0.3458 - val_accuracy: 0.8675\n",
      "Epoch 45/50\n",
      "1062/1062 - 6s - loss: 0.3255 - accuracy: 0.8786 - val_loss: 0.3534 - val_accuracy: 0.8619\n",
      "Epoch 46/50\n",
      "1062/1062 - 6s - loss: 0.3174 - accuracy: 0.8825 - val_loss: 0.6834 - val_accuracy: 0.7519\n",
      "Epoch 47/50\n",
      "1062/1062 - 6s - loss: 0.3198 - accuracy: 0.8822 - val_loss: 0.5024 - val_accuracy: 0.8040\n",
      "Epoch 48/50\n",
      "1062/1062 - 6s - loss: 0.3200 - accuracy: 0.8815 - val_loss: 0.5110 - val_accuracy: 0.8090\n",
      "Epoch 49/50\n",
      "1062/1062 - 6s - loss: 0.3174 - accuracy: 0.8824 - val_loss: 0.4027 - val_accuracy: 0.8464\n",
      "Epoch 50/50\n",
      "1062/1062 - 5s - loss: 0.3156 - accuracy: 0.8825 - val_loss: 0.4173 - val_accuracy: 0.8415\n"
     ]
    }
   ],
   "source": [
    "# build and train model\n",
    "\n",
    "model = build_model(window_size=config['model']['window_size'], depth=config['model']['depth'])\n",
    "cp_callback = ModelCheckpoint(filepath=model_path, monitor='val_accuracy', save_weights_only=True,\n",
    "                              save_best_only=True)\n",
    "\n",
    "history = model.fit(X1_train, y_train,\n",
    "                    epochs=config['training']['n_epochs'],\n",
    "                    batch_size=config['training']['batch_size'],\n",
    "                    validation_split=0.15, callbacks=[cp_callback],\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "history_path = os.path.join(model_dir, 'history.csv')\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(history_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss                 0.3471\n",
      "accuracy             0.8669\n",
      "\n",
      "r2                     0.79\n",
      "precision            0.9060  0.8276  0.8640\n",
      "recall               0.9128  0.7675  0.9198\n",
      "fscore               0.9094  0.7964  0.8910\n",
      "support               13298   13273   13398\n",
      "\n",
      "confusion matrix    \n",
      "  12139    1076      83\n",
      "   1230   10187    1856\n",
      "     29    1046   12323\n",
      "\n",
      "Metrics written to _output/models/20220214_155018/metrics.txt.\n",
      "Config copied to _output/models/20220214_155018/config.yml.\n"
     ]
    }
   ],
   "source": [
    "# load and evaluate the best model\n",
    "\n",
    "model.load_weights(model_path)\n",
    "\n",
    "loss, accuracy = model.evaluate(X1_test, y_test, verbose=0)\n",
    "\n",
    "y_pred_num = np.argmax(model.predict(X1_test), axis=1)\n",
    "y_test_num = np.argmax(y_test, axis=1)\n",
    "\n",
    "metrics = get_metrics(y_test_num, y_pred_num)\n",
    "\n",
    "output = (\n",
    "    f\"{'loss':20}{loss:7.4f}\\n\"\n",
    "    f\"{'accuracy':20}{accuracy:7.4f}\\n\\n\"\n",
    "    f\"{metrics}\"\n",
    ")\n",
    "\n",
    "print(output)\n",
    "\n",
    "f = open(metrics_path, 'w')\n",
    "f.write(output)\n",
    "f.close()\n",
    "print(f\"Metrics written to {metrics_path}.\")\n",
    "\n",
    "yaml.dump(config, open(config_path, 'w'))\n",
    "print(f\"Config copied to {config_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
